{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] TEST: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] TEST: [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54\n",
      " 55 56 57 58 59]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] TEST: [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84\n",
      " 85 86 87 88 89]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] TEST: [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119] TEST: [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "[array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
      "       [ 0.00105557,  0.00502047,  0.00105557,  0.00105557,  0.00105557,\n",
      "         0.00105557,  0.00105557,  0.00105557,  0.00502047,  0.00105557,\n",
      "         0.00105557,  0.00105557,  0.00502047,  0.00502047,  0.00105557,\n",
      "         0.00105557,  0.00105557,  0.00105557,  0.00105557,  0.00105557,\n",
      "         0.00105557,  0.00105557,  0.00105557,  0.00105557,  0.00105557,\n",
      "         0.00502047,  0.00105557,  0.00105557,  0.00105557,  0.00105557]]), array([[ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
      "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  1. ,  1. ,\n",
      "         1. ,  1. ,  1. ,  1. ,  1. ,  1. ,  1. ,  1. ],\n",
      "       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
      "         0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  1. ,  1. ,\n",
      "         1.3,  1. ,  1. ,  1. ,  1. ,  1.1,  1. ,  1. ]]), array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.],\n",
      "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  2.,\n",
      "         1.,  1.,  1.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.]]), array([[ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "         2.        ,  2.        ,  2.        ,  2.        ,  2.        ,\n",
      "         2.        ,  2.        ,  2.        ,  2.        ,  2.        ,\n",
      "         2.        ,  2.        ,  2.        ,  2.        ,  2.        ,\n",
      "         2.        ,  2.        ,  2.        ,  2.        ,  2.        ],\n",
      "       [ 1.07934466,  1.10740481,  0.96619545,  0.9387628 ,  1.04157266,\n",
      "         0.89805822,  0.97520701,  0.93217377,  0.8669234 ,  0.98231899,\n",
      "         2.10754348,  1.80823822,  2.06138211,  1.97539497,  2.15109514,\n",
      "         1.97002347,  1.32658275,  2.02375197,  1.98303997,  1.9885595 ,\n",
      "         1.72156828,  1.87725329,  1.98082941,  1.8196077 ,  2.00730036,\n",
      "         1.97588536,  1.89482287,  1.89067915,  1.7628556 ,  1.50665468]]), array([[ 2.        ,  2.        ,  2.        ,  2.        ,  2.        ,\n",
      "         2.        ,  2.        ,  2.        ,  2.        ,  2.        ,\n",
      "         2.        ,  2.        ,  2.        ,  2.        ,  2.        ,\n",
      "         2.        ,  2.        ,  2.        ,  2.        ,  2.        ,\n",
      "         2.        ,  2.        ,  2.        ,  2.        ,  2.        ,\n",
      "         2.        ,  2.        ,  2.        ,  2.        ,  2.        ],\n",
      "       [ 1.84651267,  1.67077463,  1.81709689,  1.49292766,  1.74099085,\n",
      "         1.58214495,  1.47570753,  1.48989737,  1.78801461,  1.44076854,\n",
      "         1.67081325,  1.66462607,  1.84673528,  1.3481756 ,  1.42101135,\n",
      "         1.86165449,  1.92902441,  1.56998542,  1.48015216,  1.67821892,\n",
      "         1.91266026,  1.73733297,  1.6390193 ,  1.89509476,  1.97587355,\n",
      "         1.78364475,  1.58604059,  1.62687716,  1.84111608,  1.54817668]])]\n",
      "MSE: 7.86020248866e-06\n",
      "RMSE: 0.0028036052662\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model as lm \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "class model_fac:\n",
    "    def __init__(self):\n",
    "        self.name = \"create models for train\"\n",
    "    \n",
    "    def model_set(self):\n",
    "        gbdt = GradientBoostingRegressor()\n",
    "        rf = RandomForestRegressor()\n",
    "        ab = AdaBoostRegressor()\n",
    "        svr = SVR()\n",
    "        lm1 = lm.BayesianRidge()\n",
    "        modelset = {}\n",
    "        modelset['gbdt'] = gbdt\n",
    "        modelset['rf'] = rf\n",
    "        modelset['ab'] = ab\n",
    "        modelset['svr'] = svr\n",
    "        modelset['lm1'] = lm1\n",
    "        return modelset\n",
    "def data_fold(x_data,y_data,n_splits=3):\n",
    "    '''input : N*D N*1 array\n",
    "       output : TRAIN TEST LIST'''\n",
    "    folded = []\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    for train_index, test_index in kf.split(x_data):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = x_data[train_index], x_data[test_index]\n",
    "        y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "        temp = {}\n",
    "        y_train.shape = (len(y_train),1)\n",
    "        y_test.shape = (len(y_test),1)\n",
    "        temp['train'] = np.hstack((X_train,y_train))\n",
    "        temp['test'] = np.hstack((X_test,y_test))\n",
    "        folded.append(temp)\n",
    "    return folded\n",
    "\n",
    "def step1(folded,**model):\n",
    "    if len(folded) != len(model):\n",
    "        print('model number is ',len(model),'split dataset for ',len(folded))\n",
    "        return 0\n",
    "    keys = model.keys()\n",
    "    keys = [x for x in keys]\n",
    "    step1_result = [] \n",
    "    for i in range(len(folded)):\n",
    "        train = folded[i]['train']\n",
    "        x_train = train[:,:-1]\n",
    "        y_train = train[:,-1]#lie vec  [:,-1] hang vec\n",
    "        #print('x',x_train)\n",
    "        #print('y',y_train)\n",
    "        #train\n",
    "        model[keys[i]].fit(x_train,y_train)\n",
    "        #test\n",
    "        test = folded[i]['test']\n",
    "        x_test = test[:,:-1]\n",
    "        y_test = test[:,-1]#lie vec  [:,-1] hang vec\n",
    "        pred = model[keys[i]].predict(x_test)\n",
    "        #print(y_test)\n",
    "        #print(pred)\n",
    "        step1_result.append(np.stack((y_test,pred),axis=0))\n",
    "        #break\n",
    "    return step1_result\n",
    "\n",
    "model_num = 5\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "folded = data_fold(data.data,data.target,n_splits=model_num)\n",
    "#folded\n",
    "model = model_fac()\n",
    "modelset = model.model_set()\n",
    "\n",
    "result = step1(folded,**modelset)\n",
    "print(result)\n",
    "result = np.concatenate(result,axis=1)\n",
    "result.shape\n",
    "result\n",
    "y = result[:,0]\n",
    "pred = result[:,1]\n",
    "# 用scikit-learn计算MSE\n",
    "print(\"MSE:\",mean_squared_error(y, pred))\n",
    "# 用scikit-learn计算RMSE\n",
    "print (\"RMSE:\",np.sqrt(mean_squared_error(y, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重点是使用模型选择特征、利用GBDT制造特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'int' and 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-2bc5dfcd7b55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mrfe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features_to_select\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mranks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"RFE\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrank_to_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mranking_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-2bc5dfcd7b55>\u001b[0m in \u001b[0;36mrank_to_dict\u001b[0;34m(ranks, names, order)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrank_to_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mminmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mranks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminmax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mranks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mranks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mranks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mranks\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'int' and 'map'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, RandomizedLasso)\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "#from minepy import MINE\n",
    "np.random.seed(0)\n",
    "size = 750\n",
    "X = np.random.uniform(0, 1, (size, 14))\n",
    "#\"Friedamn #1” regression problem\n",
    "Y = (10 * np.sin(np.pi*X[:,0]*X[:,1]) + 20*(X[:,2] - .5)**2 +\n",
    "    10*X[:,3] + 5*X[:,4] + np.random.normal(0,1))\n",
    "#Add 3 additional correlated variables (correlated with X1-X3)\n",
    "X[:,10:] = X[:,:4] + np.random.normal(0, .025, (size,4))\n",
    "names = [\"x%s\" % i for i in range(1,15)]\n",
    "\n",
    "ranks = {}\n",
    "def rank_to_dict(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x, 2), ranks)\n",
    "    return dict(zip(names, ranks ))\n",
    "\n",
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(X, Y)\n",
    "ranks[\"Linear reg\"] = rank_to_dict(np.abs(lr.coef_), names)\n",
    "ridge = Ridge(alpha=7)\n",
    "ridge.fit(X, Y)\n",
    "ranks[\"Ridge\"] = rank_to_dict(np.abs(ridge.coef_), names)\n",
    "lasso = Lasso(alpha=.05)\n",
    "lasso.fit(X, Y)\n",
    "ranks[\"Lasso\"] = rank_to_dict(np.abs(lasso.coef_), names)\n",
    "rlasso = RandomizedLasso(alpha=0.04)\n",
    "rlasso.fit(X, Y)\n",
    "ranks[\"Stability\"] = rank_to_dict(np.abs(rlasso.scores_), names)\n",
    "#stop the search when 5 features are left (they will get equal scores)\n",
    "rfe = RFE(lr, n_features_to_select=5)\n",
    "rfe.fit(X,Y)\n",
    "ranks[\"RFE\"] = rank_to_dict(map(float, rfe.ranking_), names, order=-1)\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X,Y)\n",
    "print(rf.feature_importances_)\n",
    "ranks[\"RF\"] = rank_to_dict(rf.feature_importances_, names)\n",
    "f, pval  = f_regression(X, Y, center=True)\n",
    "ranks[\"Corr.\"] = rank_to_dict(f, names)\n",
    "#mine = MINE()\n",
    "#mic_scores = []\n",
    "#for i in range(X.shape[1]):\n",
    "#    mine.compute_score(X[:,i], Y)\n",
    "#    m = mine.mic()\n",
    "#    mic_scores.append(m)\n",
    "#ranks[\"MIC\"] = rank_to_dict(mic_scores, names)\n",
    "r = {}\n",
    "for name in names:\n",
    "    r[name] = round(np.mean([ranks[method][name] for method in ranks.keys()]), 2)\n",
    "methods = sorted(ranks.keys())\n",
    "ranks[\"Mean\"] = r\n",
    "methods.append(\"Mean\")\n",
    "print (\"\\t%s\" % \"\\t\".join(methods))\n",
    "for name in names:\n",
    "    print(\"%s\\t%s\" % (name, \"\\t\".join(map(str, \n",
    "                        [ranks[method][name] for method in methods]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
